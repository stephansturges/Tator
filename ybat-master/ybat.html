<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>ü•î Tator Annotation Tool</title>
    <link href="ybat.css" rel="stylesheet">

    <!-- 1) Keep scripts in an order that ensures ybat.js is available  
         before we call listenImageCrop().
    -->
    <script src="canvas.min.js"></script>
    <script src="jszip.min.js"></script>
    <script src="filesaver.min.js"></script>
    <script src="ybat.js"></script>
</head>
<body>
    <div id="ingestProgress" class="ingest-progress" aria-live="polite" aria-atomic="true">
        <div id="ingestProgressLabel" class="ingest-progress__label">Loading‚Ä¶</div>
        <div id="ingestProgressDetail" class="ingest-progress__detail">0/0</div>
    </div>
    <div id="backgroundLoadModal" class="modal" aria-hidden="true">
        <div class="modal__backdrop" data-modal-dismiss="background"></div>
        <div class="modal__dialog" role="dialog" aria-modal="true" aria-labelledby="backgroundLoadTitle">
            <div class="modal__title" id="backgroundLoadTitle">Still loading‚Ä¶</div>
            <p class="modal__body" id="backgroundLoadMessage">Images and annotations are still being prepared in the background.</p>
            <div class="modal__actions">
                <button type="button" class="modal__btn modal__btn--primary" id="backgroundLoadDismiss">OK</button>
            </div>
        </div>
    </div>
    <div id="batchTweakModal" class="modal" aria-hidden="true">
        <div class="modal__backdrop" data-modal-dismiss="batchTweak"></div>
        <div class="modal__dialog" role="dialog" aria-modal="true" aria-labelledby="batchTweakTitle">
            <div class="modal__title" id="batchTweakTitle">Apply SAM tweak?</div>
            <p class="modal__body" id="batchTweakMessage">
                Apply SAM bbox tweak to all boxes in <span id="batchTweakClass">this class</span>?
            </p>
            <div class="modal__actions">
                <button type="button" class="modal__btn modal__btn--primary" id="batchTweakConfirm">Yes</button>
                <button type="button" class="modal__btn" id="batchTweakCancel">No</button>
            </div>
        </div>
    </div>
    <div id="trainingPackagingModal" class="modal" aria-hidden="true">
        <div class="modal__backdrop" data-modal-dismiss="trainingPackaging"></div>
        <div class="modal__dialog" role="dialog" aria-modal="true" aria-labelledby="trainingPackagingTitle">
            <div class="modal__title" id="trainingPackagingTitle">Packaging dataset‚Ä¶</div>
            <p class="training-packaging__stats" id="trainingPackagingStats">Estimating selection‚Ä¶</p>
            <div class="training-packaging-progress">
                <div class="training-packaging-progress__fill" id="trainingPackagingProgressFill"></div>
            </div>
            <p class="training-packaging__progress" id="trainingPackagingProgressText">Preparing‚Ä¶</p>
            <p class="training-packaging__eta" id="trainingPackagingEta">Estimating upload time‚Ä¶</p>
            <p class="training-packaging__elapsed" id="trainingPackagingElapsed">Elapsed: 0s</p>
            <p class="training-packaging__hint" id="trainingPackagingHint">Keep this tab open while we stage files and upload them to the server. Larger datasets can take a few minutes.</p>
            <div class="modal__actions">
                <button type="button" class="modal__btn" id="trainingPackagingDismiss">Hide</button>
            </div>
        </div>
    </div>
    <div id="taskQueue" class="task-queue" aria-live="polite" aria-atomic="true"></div>
    <div class="tab-shell">
        <div class="tab-bar" role="tablist">
            <button class="tab-button active" data-tab="labeling" id="tabLabelingButton" type="button">Label Images</button>
            <button class="tab-button" data-tab="training" id="tabTrainingButton" type="button">Train CLIP</button>
            <button class="tab-button" data-tab="qwen-train" id="tabQwenTrainButton" type="button">Train Qwen</button>
            <button class="tab-button" data-tab="sam3-train" id="tabSam3TrainButton" type="button">Train SAM3</button>
            <button class="tab-button" data-tab="agent-mining" id="tabAgentMiningButton" type="button">SAM3 Recipe Mining</button>
            <button class="tab-button" data-tab="prompt-helper" id="tabPromptHelperButton" type="button">SAM3 Vocabulary Explorer</button>
            <button class="tab-button" data-tab="datasets" id="tabDatasetsButton" type="button">Dataset Management</button>
            <button class="tab-button" data-tab="sam3-prompt-models" id="tabSam3PromptModelsButton" type="button">SAM3 Prompt Model Selection</button>
            <button class="tab-button" data-tab="active" id="tabActiveButton" type="button">CLIP Class Predictor Settings</button>
            <button class="tab-button" data-tab="qwen" id="tabQwenButton" type="button">Qwen Models</button>
            <button class="tab-button" data-tab="predictors" id="tabPredictorsButton" type="button">SAM Predictors</button>
            <button class="tab-button" data-tab="settings" id="tabSettingsButton" type="button">Backend Config</button>
        </div>
        <div class="tab-panels">
            <div class="tab-panel active" id="tabLabeling" data-tab-panel="labeling">
                <div class="container" id="container">
                    <div class="left">
                        <form action="">
                            <label for="images">Images:</label>
                            <input type="file" id="images" name="images[]" accept="image/jpeg, image/png" multiple class="file-input-hidden" />
                            <label for="images" id="imagesSelect" class="training-button" role="button" tabindex="0">Choose Images‚Ä¶</label>
                            <button type="button" name="cropImages" id="cropImages" class="training-button">Crop &amp; Save</button>
                            <br />
                            <label for="imageSearch">Search:</label>
                            <input type="text" id="imageSearch" name="imageSearch" />
                            <label for="imageList"></label>
                            <select name="imageList" id="imageList" size="10" multiple></select>
                            <div id="imageInformation"></div>
                            <div id="datasetTypeBadge" class="training-help"></div>
                            <div class="training-actions">
                                <button type="button" id="polygonDrawToggle" class="training-button secondary" aria-pressed="true">
                                    Polygon draw: On (P)
                                </button>
                            </div>
                            <div class="training-help">Seg mode only: P toggles polygon drawing. When off, clicks select/move polygons without adding new ones.</div>
                            <label for="classes">Classes:</label>
                            <input type="file" id="classes" name="classes" accept="text/plain" class="file-input-hidden" />
                            <label for="classes" id="classesSelect" class="training-button" role="button" tabindex="0">Load Classes‚Ä¶</label>
                            <label for="classList"></label>
                            <select name="classList" id="classList" size="10" multiple></select>
                            <div id="bboxInformation"></div>
                            <hr />
                            <div class="training-field training-field--inline">
                                <label for="autoMode">Auto Class</label>
                                <input type="checkbox" id="autoMode" name="autoMode" />
                            </div>
                            <div class="training-field training-field--inline">
                                <label for="samMode">SAM Mode</label>
                                <input type="checkbox" id="samMode" name="samMode" />
                            </div>
                            <div class="training-field">
                                <label for="samVariant">SAM Model</label>
                                <select id="samVariant" name="samVariant">
                                    <option value="sam1" selected>SAM 1</option>
                                    <option value="sam3">SAM 3</option>
                                </select>
                            </div>
                            <div class="training-field training-field--inline">
                                <label for="samPreload">Preload SAM</label>
                                <input type="checkbox" id="samPreload" name="samPreload" />
                            </div>
                            <div class="training-field training-field--inline">
                                <label for="pointMode">Point Mode</label>
                                <input type="checkbox" id="pointMode" name="pointMode" />
                            </div>
                            <div class="training-field training-field--inline">
                                <label for="multiPointMode">Multi-Point Mode</label>
                                <input type="checkbox" id="multiPointMode" name="multiPointMode" />
                            </div>
                            <div class="training-field" id="polygonSimplifyField">
                                <label for="polygonSimplifyEpsilon">Polygon detail</label>
                                <input type="range" id="polygonSimplifyEpsilon" name="polygonSimplifyEpsilon" min="0" max="40" step="0.5" value="20" />
                                <div class="training-help">Left = simpler polygons, right = more detail (more points).</div>
                            </div>
                            <div id="samStatus" class="sam-status" role="status" aria-live="polite"></div>
                            <div id="samStatusProgress" class="sam-status-progress" aria-hidden="true">
                                <div id="samStatusProgressFill"></div>
                            </div>
                            <br />
                            <div id="sam3SimilarityRow" class="training-actions" style="margin-bottom: 12px;">
                                <button type="button" id="sam3SimilarityButton" class="training-button secondary">
                                    SAM3 similarity prompt (use selected box)
                                </button>
                                <label for="sam3SimilarityThreshold" class="training-help" style="margin-top: 6px;">Similarity score (higher = stricter)</label>
                                <input type="range" id="sam3SimilarityThreshold" min="0" max="1" step="0.05" value="0.5" />
                            </div>
                            <section class="qwen-panel" aria-labelledby="qwenPanelTitle">
                                <div class="qwen-panel__header">
                                    <span id="qwenPanelTitle">Qwen 2.5 Assist</span>
                                    <span id="qwenActiveModelLabel" class="qwen-active-model-label"></span>
                                    <span id="qwenStatusLabel" class="qwen-status-label">Checking‚Ä¶</span>
                                </div>
                                <label for="qwenItems">Objects / keywords</label>
                                <textarea id="qwenItems" rows="3" placeholder="List what to detect (comma or line separated)"></textarea>
                                <button type="button" id="qwenAdvancedToggle" class="qwen-advanced-toggle" aria-expanded="false">Show advanced overrides</button>
                                <div id="qwenAdvancedPanel" class="qwen-advanced" aria-hidden="true">
                                    <label for="qwenCustomPrompt">Full prompt override</label>
                                    <textarea id="qwenCustomPrompt" rows="3" placeholder="Optional: supply the exact prompt to send to Qwen"></textarea>
                                    <label for="qwenImageType">Image type description</label>
                                    <input type="text" id="qwenImageType" placeholder="Pulled from active Qwen model" />
                                    <label for="qwenExtraContext">Extra context</label>
                                    <textarea id="qwenExtraContext" rows="2" placeholder="Optional notes (lighting, camera, etc.)"></textarea>
                                </div>
                                <label for="qwenClassSelect">Assign detections to class</label>
                                <select id="qwenClassSelect"></select>
                                <label for="qwenPromptType">Prompt output</label>
                                <select id="qwenPromptType">
                                    <option value="bbox" selected>Bounding boxes</option>
                                    <option value="bbox_sam">Bounding boxes ‚Üí SAM cleanup</option>
                                    <option value="point">Points ‚Üí SAM boxes</option>
                                </select>
                                <label for="qwenMaxResults">Max detections</label>
                                <input type="number" id="qwenMaxResults" min="1" max="50" value="8" />
                                <button type="button" id="qwenRunButton" class="training-button" disabled>Use Qwen</button>
                                <p class="qwen-hint">Uses the prompts saved with the active Qwen model; add extra context via the advanced overrides when needed.</p>
                                <section class="sam3-text-panel" id="sam3TextPanel" aria-labelledby="sam3TextTitle">
                                    <div class="sam3-text-panel__header">
                                        <span id="sam3TextTitle"><strong>SAM3 Text Prompt</strong></span>
                                        <span id="sam3TextStatus" class="sam3-text-status" aria-live="polite"></span>
                                    </div>
                                    <p class="sam3-text-hint">Runs text-driven segmentation with SAM3. Can be used alongside the bbox tools.</p>
                                    <label for="sam3TextPrompt">Prompt (describe what to segment)</label>
                                    <input type="text" id="sam3TextPrompt" placeholder="e.g., red helmet" />
                                    <div class="sam3-text-grid">
                                        <label for="sam3Threshold">Score threshold</label>
                                        <input type="number" id="sam3Threshold" step="0.05" min="0" max="1" value="0.5" />
                                        <label for="sam3MaskThreshold">Mask threshold</label>
                                        <input type="number" id="sam3MaskThreshold" step="0.05" min="0" max="1" value="0.5" />
                                        <label for="sam3MaxResults">Max results</label>
                                        <input type="number" id="sam3MaxResults" min="1" max="100" value="20" />
                                        <label for="sam3MinSize">Min size (px¬≤)</label>
                                        <input type="number" id="sam3MinSize" min="0" value="0" title="Ignore detections smaller than this pixel area. 0 keeps all." />
                                        <label for="sam3MaxPoints">Max points/polygon</label>
                                        <input type="number" id="sam3MaxPoints" min="10" max="5000" value="500" title="Simplification cap per polygon. Lower for smoother shapes; higher preserves detail." />
                                        <label for="sam3SimplifyEpsilon">Simplify epsilon (px)</label>
                                        <input type="number" id="sam3SimplifyEpsilon" min="0" step="0.1" value="1.0" title="Douglas‚ÄìPeucker epsilon in pixels on the downsampled mask: higher = smoother polygons, lower = more detail." />
                                    </div>
	                                    <label for="sam3ClassSelect">Assign detections to class</label>
	                                    <select id="sam3ClassSelect"></select>
	                                    <div class="sam3-text-buttons">
	                                        <button type="button" id="sam3RunButton" class="training-button">Run SAM3</button>
	                                        <button type="button" id="sam3RunAutoButton" class="training-button">Run SAM3 + Auto Class</button>
	                                        <label for="sam3RecipeFile" class="training-button secondary" title="Load a portable recipe zip (from Agent Mining or another machine). It contains a JSON recipe + example crops.">Load recipe (zip)</label>
	                                        <input type="file" id="sam3RecipeFile" accept=".zip" class="file-input-hidden" />
	                                        <div class="training-grid" style="grid-template-columns: 1fr 1fr;">
	                                            <div>
	                                                <label for="sam3RecipePresetSelect" title="Saved recipes on the backend. Use Refresh if you just mined/imported a recipe.">Recipe presets</label>
	                                                <select id="sam3RecipePresetSelect" title="Saved recipes on the backend. Use Refresh if you just mined/imported a recipe."></select>
	                                            </div>
	                                            <div>
	                                                <label for="sam3RecipePresetName" title="Optional friendly name when saving the currently loaded recipe into your preset list.">Save preset as</label>
	                                                <input type="text" id="sam3RecipePresetName" placeholder="Optional label" />
	                                            </div>
	                                        </div>
	                                        <div class="training-grid" style="grid-template-columns: 1fr 1fr;">
	                                            <label title="Assign detections to a different class than the recipe‚Äôs default (useful when applying a recipe to a dataset with different class names)."><input type="checkbox" id="sam3RecipeOverrideToggle" /> Override output class</label>
	                                            <select id="sam3RecipeOverrideSelect" disabled></select>
	                                        </div>
	                                        <div class="training-actions">
	                                            <button type="button" id="sam3RecipePresetRefresh" class="training-button secondary">Refresh</button>
	                                            <button type="button" id="sam3RecipePresetSave" class="training-button secondary">Save recipe preset</button>
	                                            <button type="button" id="sam3RecipePresetLoad" class="training-button secondary">Load preset</button>
	                                            <button type="button" id="sam3RecipePresetDelete" class="training-button danger">Delete preset</button>
	                                            <button type="button" id="sam3RecipeApplyButton" class="training-button secondary">Apply recipe to image</button>
	                                        </div>
	                                        <div class="training-help">
	                                            Recipes are saved ‚Äúfind this object‚Äù strategies from the <strong>SAM3 Recipe Mining</strong> tab. Load a recipe zip or pick a preset, then click ‚ÄúApply recipe to image‚Äù to add boxes/polygons to the current image.
	                                        </div>
	                                        <div id="sam3RecipeStatus" class="training-help" aria-live="polite"></div>
	                                    </div>
	                                </section>
                            </section>
                            <br />
                            <hr />
                            <label for="bboxes">Bboxes:</label>
                            <input type="file" id="bboxes" name="bboxes[]" accept="text/plain,application/zip" disabled multiple class="file-input-hidden" />
                            <label for="bboxes" id="bboxesSelect" class="training-button button-disabled" aria-disabled="true" role="button" tabindex="-1">Import Bboxes‚Ä¶</label>
                            <input type="file" id="bboxesFolder" name="bboxesFolder[]" accept="text/plain" disabled multiple webkitdirectory directory class="file-input-hidden" />
                            <label for="bboxesFolder" id="bboxesSelectFolder" class="training-button button-disabled" aria-disabled="true" role="button" tabindex="-1">Import Bboxes Folder‚Ä¶</label>
                            <button type="button" name="saveBboxes" id="saveBboxes" class="training-button">Save YOLO</button>
                            <hr />
                            <div id="description">
                                SHORTCUTS:
                                <ul>
                                    <li><strong>X</strong> ‚Äî press with a bbox selected to run the SAM tweak</li>
                                    <li><strong>X</strong> twice ‚Äî batch tweak all bboxes in the class currently selected in the list</li>
                                    <li>Mouse wheel ‚Äî zoom</li>
                                    <li>Shift + wheel ‚Äî pan</li>
                                    <li>Right-click drag ‚Äî pan</li>
                                    <li>‚Üê / ‚Üí ‚Äî cycle images</li>
                                    <li>‚Üë / ‚Üì ‚Äî cycle classes</li>
                                    <li>Delete / Backspace / W ‚Äî remove selected bbox</li>
                                    <li>Q ‚Äî delete the most recently created bbox</li>
                                    <li>Enter ‚Äî submit multi-point mask</li>
                                    <li>Hold Z ‚Äî temporarily disable Auto Class and all SAM modes so you can select or delete the active bbox</li>
                                    <li>A ‚Äî toggle auto class</li>
                                    <li>S ‚Äî toggle SAM</li>
                                    <li>D ‚Äî toggle SAM point mode</li>
                                    <li>M ‚Äî toggle SAM multi-point</li>
                                    <li>F ‚Äî add positive point</li>
                                    <li>G ‚Äî add negative point</li>
                                </ul>
                            </div>
                        </form>
                    </div>
                    <div class="right" id="right">
                        <div id="clipProgressBar"><div id="clipProgressFill"></div></div>
                        <canvas id="canvas"></canvas>
                        <canvas id="hiddenCanvas"></canvas>
                    </div>
                </div>
            </div>
            <div class="tab-panel" id="tabTraining" data-tab-panel="training">
                <div class="training-wrapper two-col">
                    <section class="training-form-section">
                        <h2>CLIP Class Predictor Settings</h2>
                        <div class="training-field">
                            <label for="clipBackboneSelect">CLIP Backbone</label>
                            <select id="clipBackboneSelect"></select>
                        </div>
                        <div class="training-field">
                            <label for="qwenTrainDevices">Device IDs</label>
                            <input type="text" id="qwenTrainDevices" placeholder="e.g., 0,1" />
                            <div class="training-help">Leave blank to use a single GPU. Enter comma-separated CUDA device indices to split across multiple GPUs.</div>
                        </div>
                        <div class="training-field">
                            <label for="trainSolver">Solver</label>
                            <select id="trainSolver">
                                <option value="saga" selected>SAGA (elastic net-friendly)</option>
                                <option value="lbfgs">LBFGS</option>
                                <option value="liblinear">LibLinear</option>
                                <option value="sag">SAG</option>
                                <option value="newton-cg">Newton-CG</option>
                            </select>
                        </div>
                        <div class="training-field">
                            <label for="trainDatasetSelect">Cached dataset (YOLO)</label>
                            <div class="training-picker">
                                <select id="trainDatasetSelect">
                                    <option value="">Use local upload‚Ä¶</option>
                                </select>
                                <button type="button" class="training-button secondary" id="trainDatasetRefresh">Refresh</button>
                            </div>
                            <div class="training-help" id="trainDatasetSummary">Choose a cached YOLO dataset or upload folders below.</div>
                        </div>
                        <div class="training-field">
                            <label for="trainImagesBtn">Images Folder</label>
                            <div class="training-picker">
                                <button type="button" class="training-button" id="trainImagesBtn">Choose folder‚Ä¶</button>
                                <input type="file" id="trainImages" accept="image/jpeg,image/png,image/webp,image/bmp,image/tiff" webkitdirectory directory multiple class="file-input-hidden" />
                            </div>
                            <div class="training-help" id="trainImagesSummary">No folder selected</div>
                        </div>
                        <div class="training-field">
                            <label for="trainLabelsBtn">Labels Folder (YOLO txt)</label>
                            <div class="training-picker">
                                <button type="button" class="training-button" id="trainLabelsBtn">Choose folder‚Ä¶</button>
                                <input type="file" id="trainLabels" accept="text/plain" webkitdirectory directory multiple class="file-input-hidden" />
                            </div>
                            <div class="training-help" id="trainLabelsSummary">No folder selected</div>
                        </div>
                        <div class="training-field">
                            <label for="trainLabelmap">Labelmap (.txt or .pkl)</label>
                            <input type="file" id="trainLabelmap" accept=".txt,.pkl" />
                            <div class="training-help" id="trainLabelmapSummary">Optional</div>
                        </div>
                        <div class="training-field">
                            <label for="trainOutputDirBtn">Output Directory</label>
                            <button type="button" class="training-button" id="trainOutputDirBtn">Choose folder‚Ä¶</button>
                            <div class="training-help" id="trainOutputDirSummary">Server default (.)</div>
                        </div>
                        <div class="training-field-double">
                            <div>
                                <label for="trainModelFilename">Model Filename</label>
                                <input type="text" id="trainModelFilename" value="my_logreg_model.pkl" />
                            </div>
                            <div>
                                <label for="trainLabelmapFilename">Labelmap Filename</label>
                                <input type="text" id="trainLabelmapFilename" value="my_label_list.pkl" />
                            </div>
                        </div>
                        <div class="training-advanced-grid">
                            <div>
                                <label for="trainTestSize">Test Size</label>
                                <input type="number" id="trainTestSize" min="0" max="0.9" step="0.05" value="0.2" />
                                <div class="training-help">Fraction of images reserved for evaluation.</div>
                            </div>
                            <div>
                                <label for="trainRandomSeed">Seed</label>
                                <input type="number" id="trainRandomSeed" value="42" />
                                <div class="training-help">Controls deterministic train/test split.</div>
                            </div>
                            <div>
                                <label for="trainBatchSize">Batch Size</label>
                                <input type="number" id="trainBatchSize" value="64" min="1" />
                                <div class="training-help">Images encoded per CLIP forward pass.</div>
                            </div>
                            <div>
                                <label for="trainMaxIter">Max Iter</label>
                                <input type="number" id="trainMaxIter" value="1000" min="100" step="50" />
                                <div class="training-help">Upper bound on solver iterations.</div>
                            </div>
                            <div>
                                <label for="trainMinPerClass">Min / Class</label>
                                <input type="number" id="trainMinPerClass" value="2" min="1" />
                                <div class="training-help">Drops classes with fewer samples before training.</div>
                            </div>
                            <div>
                                <label for="trainRegC">C</label>
                                <input type="number" id="trainRegC" value="1.0" step="0.1" min="0.01" />
                                <div class="training-help">Inverse regularisation strength (higher = less regularisation).</div>
                            </div>
                            <div>
                                <label for="trainClassWeight">Class Weight</label>
                                <select id="trainClassWeight">
                                    <option value="none" selected>None</option>
                                    <option value="balanced">Balanced</option>
                                </select>
                                <div class="training-help">`balanced` reweights rare classes; `none` leaves raw counts.</div>
                            </div>
                            <div>
                                <label for="trainDeviceOverride">Device Override</label>
                                <input type="text" id="trainDeviceOverride" placeholder="cpu or cuda" />
                            </div>
                            <div>
                                <label for="trainHardMisWeight">Hard W (misclass)</label>
                                <input type="number" id="trainHardMisWeight" value="3.0" min="1" step="0.1" />
                                <div class="training-help">Multiplier applied to misclassified samples in hard mining.</div>
                            </div>
                            <div>
                                <label for="trainHardLowConfWeight">Hard W (low conf)</label>
                                <input type="number" id="trainHardLowConfWeight" value="2.0" min="1" step="0.1" />
                                <div class="training-help">Multiplier for low-confidence samples (below the thresholds).</div>
                            </div>
                            <div>
                                <label for="trainHardLowConfThreshold">Low-conf threshold</label>
                                <input type="number" id="trainHardLowConfThreshold" value="0.65" min="0" max="0.9999" step="0.01" />
                                <div class="training-help">Samples with max probability below this value get boosted.</div>
                            </div>
                            <div>
                                <label for="trainHardMarginThreshold">Margin threshold</label>
                                <input type="number" id="trainHardMarginThreshold" value="0.15" min="0" max="1" step="0.01" />
                                <div class="training-help">Boost samples whose top-1 vs top-2 gap falls under this margin.</div>
                            </div>
                            <div>
                                <label for="trainConvergenceTol">Convergence tol</label>
                                <input type="number" id="trainConvergenceTol" value="0.0001" min="0" step="0.00001" />
                                <div class="training-help">Lower tolerance forces more iterations before convergence.</div>
                            </div>
                        </div>
                        <button type="button" id="startTrainingBtn">Start Training</button>
                        <div class="training-toggle-row">
                            <label><input type="checkbox" id="trainReuseEmbeddings" checked /> Cache and reuse embeddings</label>
                            <label><input type="checkbox" id="trainHardMining" /> Hard example mining</label>
                        </div>
                        <div class="training-message" id="trainingMessage" role="status"></div>
                    </section>
                    <section class="training-status-section">
                        <h2>Training Status</h2>
                        <div class="training-progress" id="trainingProgressBar">
                            <div class="training-progress-fill" id="trainingProgressFill"></div>
                        </div>
                        <div class="training-status-text" id="trainingStatusText">Idle</div>
                        <div class="training-actions">
                            <button type="button" class="training-button training-button-danger" id="cancelTrainingBtn" disabled>Cancel Job</button>
                        </div>
                        <div class="training-summary" id="trainingSummary"></div>
                        <div class="training-logs">
                            <h3>Logs</h3>
                            <pre id="trainingLog"></pre>
                        </div>
                        <div class="training-history">
                            <h3>Recent Jobs</h3>
                            <div id="trainingHistory"></div>
                        </div>
                    </section>
                </div>
            </div>
            <div class="tab-panel" id="tabQwenTrain" data-tab-panel="qwen-train">
                <div class="training-wrapper two-col">
                    <section class="training-form-section">
                        <h2>Fine-tune Qwen 2.5 VL</h2>
                        <p class="qwen-train-intro">
                            Turn the images + YOLO boxes you have loaded into a Qwen fine-tuning dataset. We will package them automatically and train
                            Qwen to respond with JSON detections (bbox + point) for every class in your label map.
                        </p>
                        <div class="qwen-train-callouts">
                            <div>
                                <strong>LoRA</strong>
                                <p>Trains lightweight adapters on top of the base FP16 model. Fast and easy when you have ‚â•24&nbsp;GB VRAM.</p>
                            </div>
                            <div>
                                <strong>QLoRA</strong>
                                <p>Quantizes the base model to 4-bit (NF4) and only trains adapters. Ideal for 18‚Äì24&nbsp;GB GPUs.</p>
                            </div>
                        </div>
                        <p class="qwen-train-note">
                            Each training sample reuses your description plus the system prompt here. For every epoch we randomly ask Qwen to return
                            either bounding boxes or click points, and we vary the scope of the request: sometimes all classes, sometimes a single class
                            that exists in the image, and sometimes a small subset. The targets are filtered to match that instruction so the adapters learn
                            both broad sweeps and class-specific prompts without duplicating the dataset on disk.
                        </p>
                        <div class="training-field">
                            <label for="qwenTrainRunName">Run name / subfolder</label>
                            <input type="text" id="qwenTrainRunName" placeholder="Optional; defaults to job id" />
                            <div class="training-help">Checkpoints land in <code>uploads/qwen_runs/&lt;run_name&gt;</code>.</div>
                        </div>
                        <div class="training-field">
                            <label for="qwenTrainContext">Describe these images</label>
                            <textarea id="qwenTrainContext" rows="2" placeholder="e.g., CCTV footage inside a warehouse"></textarea>
                            <div class="training-help">Used to enrich the prompt we send for every image.</div>
                        </div>
                        <div class="training-field">
                            <label>Dataset source</label>
                            <div class="qwen-dataset-modes">
                                <label><input type="radio" name="qwenDatasetMode" id="qwenDatasetModeUpload" value="upload" checked /> Upload current dataset</label>
                                <label><input type="radio" name="qwenDatasetMode" id="qwenDatasetModeCached" value="cached" /> Reuse cached dataset</label>
                            </div>
                            <div class="qwen-dataset-cache-controls">
                                <select id="qwenDatasetSelect" disabled></select>
                                <button type="button" class="training-button" id="qwenDatasetRefresh" disabled>Refresh</button>
                                <button type="button" class="training-button training-button-danger" id="qwenDatasetDelete" disabled>Delete</button>
                            </div>
                            <div class="training-help" id="qwenDatasetSummary">We'll package the dataset from the labeling tab and cache it automatically.</div>
                        </div>
                        <div class="training-grid">
                            <div class="checkbox-row">
                                <label><input type="checkbox" id="qwenTrainRandomSplit" checked /> Random split (ignore existing train/val)</label>
                            </div>
                            <div>
                                <label for="qwenTrainValPercent">Val %</label>
                                <input type="number" id="qwenTrainValPercent" min="1" max="90" value="30" />
                            </div>
                            <div>
                                <label for="qwenTrainSplitSeed">Split seed</label>
                                <input type="number" id="qwenTrainSplitSeed" value="42" />
                            </div>
                        </div>
                        <div class="training-help">We rebuild the train/val split per job using this seed and percentage.</div>
                        <div class="training-grid">
                            <div class="training-help" id="qwenCacheInfo">Split cache: ‚Ä¶</div>
                            <div>
                                <button id="qwenCachePurge" class="secondary">Purge split cache</button>
                            </div>
                        </div>
                        <div class="training-field">
                            <label for="qwenTrainModelId">Base model repo</label>
                            <input type="text" id="qwenTrainModelId" value="Qwen/Qwen2.5-VL-3B-Instruct" />
                        </div>
                        <div class="training-field">
                            <label for="qwenTrainSystemPrompt">System prompt</label>
                            <textarea id="qwenTrainSystemPrompt" rows="3">You are an annotation assistant that only returns JSON shaped like {"detections":[{"label":"class","bbox":[x1,y1,x2,y2]} or {"label":"class","point":[x,y]}]}. Respond with JSON only.</textarea>
                            <div class="training-help">Shared system message for every conversation. The user prompt still toggles between bbox vs. point instructions per sample.</div>
                        </div>
                        <div class="training-field">
                            <label for="qwenTrainPromptNoise">System prompt noise (0‚Äì0.30)</label>
                            <input type="number" id="qwenTrainPromptNoise" min="0" max="0.3" step="0.01" value="0.05" />
                            <div class="training-help">We randomly drop this fraction of characters from the system prompt for each sample to make the model more robust.</div>
                        </div>
                        <div class="training-field">
                            <label for="qwenTrainAccelerator">Accelerator</label>
                            <select id="qwenTrainAccelerator">
                                <option value="gpu" selected>GPU (recommended)</option>
                                <option value="auto">Auto</option>
                                <option value="cpu">CPU (debug only)</option>
                            </select>
                        </div>
                        <fieldset class="qwen-radio-group">
                            <legend>Adapter strategy</legend>
                            <label class="qwen-radio">
                                <input type="radio" name="qwenLoraMode" value="qlora" checked />
                                <span>
                                    <strong>QLoRA (default)</strong>
                                    <small>Quantize the backbone to 4-bit NF4 and train adapters. Lower VRAM, same accuracy.</small>
                                </span>
                            </label>
                            <label class="qwen-radio">
                                <input type="radio" name="qwenLoraMode" value="lora" />
                                <span>
                                    <strong>LoRA</strong>
                                    <small>Keep the base model in FP16/BF16 and only train adapters. Requires more VRAM but slightly simpler.</small>
                                </span>
                            </label>
                        </fieldset>
                        <div class="training-advanced-grid">
                            <div>
                                <label for="qwenTrainBatchSize">Batch size</label>
                                <input type="number" id="qwenTrainBatchSize" value="1" min="1" />
                            </div>
                            <div>
                                <label for="qwenTrainEpochs">Max epochs</label>
                                <input type="number" id="qwenTrainEpochs" value="10" min="1" />
                            </div>
                            <div>
                                <label for="qwenTrainLR">Learning rate</label>
                                <input type="number" step="0.00001" id="qwenTrainLR" value="0.0002" />
                            </div>
                            <div>
                                <label for="qwenTrainAccumulate">Gradient accumulation</label>
                                <input type="number" id="qwenTrainAccumulate" value="8" min="1" />
                            </div>
                            <div>
                                <label for="qwenTrainDevices">Device IDs</label>
                                <input type="text" id="qwenTrainDevices" placeholder="e.g., 0,1" />
                                <div class="training-help">Leave blank for a single GPU. Enter comma-separated CUDA IDs to train on multiple GPUs.</div>
                            </div>
                            <div>
                                <label for="qwenTrainLoraRank">LoRA rank</label>
                                <input type="number" id="qwenTrainLoraRank" value="8" min="1" />
                            </div>
                            <div>
                                <label for="qwenTrainLoraAlpha">LoRA alpha</label>
                                <input type="number" id="qwenTrainLoraAlpha" value="16" min="1" />
                            </div>
                            <div>
                                <label for="qwenTrainLoraDropout">LoRA dropout</label>
                                <input type="number" id="qwenTrainLoraDropout" value="0.05" step="0.01" min="0" max="1" />
                            </div>
                            <div>
                                <label for="qwenTrainPatience">Early stop patience</label>
                                <input type="number" id="qwenTrainPatience" value="3" min="1" />
                            </div>
                            <div>
                                <label for="qwenTrainMaxImageDim">Max image dimension (px)</label>
                                <input type="number" id="qwenTrainMaxImageDim" value="1024" min="256" max="4096" step="64" />
                                <div class="training-help">Images larger than this shrink on the longest side before reaching Qwen.</div>
                            </div>
                            <div>
                                <label for="qwenTrainMaxDetections">Max detections per sample</label>
                                <input type="number" id="qwenTrainMaxDetections" value="200" min="1" max="200" />
                                <div class="training-help">Uses the same per-class-aware cap from the trainer; drop below 200 to ease VRAM pressure.</div>
                            </div>
                        </div>
                        <div class="training-actions">
                            <button type="button" class="training-button" id="qwenTrainStartBtn">Start Training</button>
                            <button type="button" class="training-button training-button-danger" id="qwenTrainCancelBtn" disabled>Cancel Job</button>
                        </div>
                        <div class="training-message" id="qwenTrainMessage" role="status"></div>
                    </section>
                    <section class="training-status-section">
                        <h2>Qwen Training Status</h2>
                        <div class="training-progress" id="qwenTrainProgressBar">
                            <div class="training-progress-fill" id="qwenTrainProgressFill"></div>
                        </div>
                        <div class="training-status-text" id="qwenTrainStatusText">Idle</div>
                        <div class="training-epoch-detail" id="qwenTrainEpochDetail">Waiting for telemetry‚Ä¶</div>
                        <div class="training-chart">
                            <div class="training-chart-header">
                                <h3>Training Loss</h3>
                                <label class="chart-smoothing">
                                    Smoothing
                                    <select id="qwenTrainChartSmoothing">
                                        <option value="1">None</option>
                                        <option value="5">5-point</option>
                                        <option value="15" selected>15-point</option>
                                    </select>
                                </label>
                            </div>
                            <canvas id="qwenTrainLossCanvas"></canvas>
                            <div class="training-help" id="qwenTrainChartStatus">Loss telemetry will appear while a job is running.</div>
                        </div>
                        <div class="qwen-sample-panel">
                            <div class="qwen-sample-header">
                                <h3>Random Training Sample</h3>
                                <button type="button" class="training-button" id="qwenSampleBtn">Generate random Qwen data sample</button>
                            </div>
                            <div class="qwen-sample-canvas">
                                <canvas id="qwenSampleCanvas" width="320" height="240"></canvas>
                                <div class="qwen-sample-status" id="qwenSampleMessage">Load images + label map, then click the button to preview how a training conversation is constructed.</div>
                            </div>
                            <div class="qwen-sample-meta" id="qwenSampleMeta"></div>
                            <div class="qwen-sample-details">
                                <label>Prompt sent to Qwen</label>
                                <pre id="qwenSamplePrompt"></pre>
                                <label>Expected JSON response</label>
                                <pre id="qwenSampleExpected"></pre>
                            </div>
                        </div>
                        <div class="training-summary" id="qwenTrainSummary"></div>
                        <div class="training-logs">
                            <h3>Logs</h3>
                            <pre id="qwenTrainLog"></pre>
                        </div>
                        <div class="training-history">
                            <h3>Recent Qwen Jobs</h3>
                            <div id="qwenTrainHistory"></div>
                        </div>
                    </section>
                </div>
            </div>
            <div class="tab-panel" id="tabSam3Train" data-tab-panel="sam3-train">
                <div class="training-wrapper two-col">
                    <section class="training-form-section">
                        <h2>Train SAM3 (text-promptable by default)</h2>
                        <p class="training-help">Pick a cached dataset (Qwen uploads or YOLO folders). By default we keep the SAM3 segmentation head so the resulting checkpoint works with text prompting; masks are only required if you opt in below.</p>
                        <div class="training-field">
                            <label>Dataset</label>
                            <div class="sam3-dataset-row">
                                <select id="sam3DatasetSelect"></select>
                                <button type="button" class="training-button" id="sam3DatasetRefresh">Refresh</button>
                                <button type="button" class="training-button" id="sam3DatasetConvert">Convert</button>
                            </div>
                            <div class="training-help" id="sam3DatasetSummary">We‚Äôll auto-convert to COCO when needed.</div>
                        </div>
                        <div class="training-grid">
                            <div class="checkbox-row">
                                <label><input type="checkbox" id="sam3RandomSplit" checked /> Random split (ignore existing train/val)</label>
                            </div>
                            <div>
                                <label for="sam3ValPercent">Val %</label>
                                <input type="number" id="sam3ValPercent" min="1" max="90" value="20" />
                            </div>
                            <div>
                                <label for="sam3SplitSeed">Split seed</label>
                                <input type="number" id="sam3SplitSeed" value="42" />
                            </div>
                        </div>
                        <div class="training-help">Train/val splits are rebuilt deterministically per job using this seed.</div>
                        <div class="training-grid">
                            <div class="training-help" id="sam3CacheInfo">Split cache: ‚Ä¶</div>
                            <div>
                                <button id="sam3CachePurge" class="secondary">Purge split cache</button>
                            </div>
                        </div>
                        <div class="training-field">
                            <label for="sam3RunName">Run name / log dir</label>
                            <input type="text" id="sam3RunName" placeholder="Optional; defaults to job id" />
                            <div class="training-help">Logs + checkpoints land in <code>uploads/sam3_runs/&lt;run_name&gt;</code>.</div>
                        </div>
                        <div class="training-grid">
                            <div>
                                <label for="sam3TrainBatch">Train batch size</label>
                                <input type="number" id="sam3TrainBatch" min="1" value="1" />
                            </div>
                            <div>
                                <label for="sam3ValBatch">Val batch size</label>
                                <input type="number" id="sam3ValBatch" min="1" value="1" />
                            </div>
                            <div>
                                <label for="sam3TrainWorkers">Train workers</label>
                                <input type="number" id="sam3TrainWorkers" min="0" value="4" />
                            </div>
                            <div>
                                <label for="sam3ValWorkers">Val workers</label>
                                <input type="number" id="sam3ValWorkers" min="0" value="2" />
                            </div>
                            <div>
                                <label for="sam3Epochs">Max epochs</label>
                                <input type="number" id="sam3Epochs" min="1" value="20" />
                            </div>
                            <div>
                                <label for="sam3Resolution">Resolution</label>
                                <input type="number" id="sam3Resolution" min="256" value="1008" step="16" />
                            </div>
                            <div>
                                <label for="sam3LrScale">LR scale</label>
                                <input type="number" id="sam3LrScale" step="0.01" value="0.1" />
                            </div>
                            <div>
                                <label for="sam3GradAccum">Grad accumulation</label>
                                <input type="number" id="sam3GradAccum" min="1" value="1" />
                            </div>
                            <div>
                                <label for="sam3ValFreq">Val every N epochs</label>
                                <input type="number" id="sam3ValFreq" min="1" value="10" />
                            </div>
                            <div>
                                <label for="sam3ValScoreThresh">Val score threshold</label>
                                <input type="number" id="sam3ValScoreThresh" step="0.01" min="0" max="1" value="0.2" title="Drop detections below this score before COCO eval." />
                            </div>
                            <div>
                                <label for="sam3ValMaxDets">Val max detections per image</label>
                                <input type="number" id="sam3ValMaxDets" min="1" value="1000" title="Keep only the top N detections per image before COCO eval." />
                            </div>
                            <div class="checkbox-row">
                                <label><input type="checkbox" id="sam3CapEpoch" checked /> Cap epoch size</label>
                                <label for="sam3TargetEpochSize">Batches per epoch</label>
                                <input type="number" id="sam3TargetEpochSize" min="1" value="1500" title="Number of batches to treat as one epoch. When capped, epochs stop after this many batches even if the dataset is larger." />
                            </div>
                            <div class="checkbox-row">
                                <label><input type="checkbox" id="sam3CapVal" /> Cap validation size</label>
                                <label for="sam3ValCapSize">Val images</label>
                                <input type="number" id="sam3ValCapSize" min="1" value="200" disabled title="Optional cap on number of validation images for quick smoke tests." />
                            </div>
                            <div>
                                <label for="sam3BalanceStrategy" title="Choose how to rebalance rare classes.">
                                    Balance strategy
                                </label>
                                <select id="sam3BalanceStrategy">
                                    <option value="none" selected>None (uniform sampling)</option>
                                    <option value="inv_sqrt">Mild: 1/sqrt(freq)</option>
                                    <option value="clipped_inv">Clipped inverse-freq</option>
                                    <option value="effective_num">Effective number of samples</option>
                                    <option value="focal">Focal sampling</option>
                                </select>
                                <div id="sam3BalanceDescription" class="training-help"></div>
                            </div>
                            <div class="balance-param-row sam3-balance-param" data-param="power">
                                <label for="sam3BalancePower" title="Exponent for inverse-frequency weighting (1/freq^power). Lower = milder.">
                                    Inverse power
                                </label>
                                <input type="number" id="sam3BalancePower" step="0.1" min="0" value="0.5" />
                            </div>
                            <div class="balance-param-row sam3-balance-param" data-param="clip">
                                <label for="sam3BalanceClip" title="Clamp the ratio between highest and lowest weights. e.g., 10 means rare classes get at most 10x the weight of common classes.">
                                    Clip ratio (max/min)
                                </label>
                                <input type="number" id="sam3BalanceClip" step="1" min="1" value="10" />
                            </div>
                            <div class="balance-param-row sam3-balance-param" data-param="beta">
                                <label for="sam3BalanceBeta" title="Beta for effective number of samples weighting. Higher (0.99-0.999) = stronger emphasis on rare classes.">
                                    Beta (effective num)
                                </label>
                                <input type="number" id="sam3BalanceBeta" step="0.001" min="0" max="0.9999" value="0.99" />
                            </div>
                            <div class="balance-param-row sam3-balance-param" data-param="gamma">
                                <label for="sam3BalanceGamma" title="Gamma for focal-style sampling. Higher = more boost to rare/low-freq classes.">
                                    Gamma (focal)
                                </label>
                                <input type="number" id="sam3BalanceGamma" step="0.1" min="0" value="0.5" />
                            </div>
                            <div>
                                <label for="sam3Warmup">Warmup steps</label>
                                <input type="number" id="sam3Warmup" min="0" value="20" title="Warmup steps: start the LR near zero and ramp up over this many steps. Higher = gentler/safer start, lower = hotter start. 0 disables warmup." />
                            </div>
                            <div>
                                <label for="sam3Timescale">Scheduler timescale</label>
                                <input type="number" id="sam3Timescale" min="1" value="20" title="Scheduler timescale: stretches the LR schedule. Higher = slower decay, steadier training. Lower = faster decay, spikier early changes." />
                            </div>
                        </div>
                        <div class="training-toggle-row">
                            <label title="For debugging only: prints a log line every minibatch (instead of every Nth). Creates very large logs."><input type="checkbox" id="sam3LogAll" /> Log every minibatch (very verbose)</label>
                        </div>
                        <div class="training-toggle-row">
                            <label title="Stops updating the language/text encoder to preserve base vocabulary. Overrides the language LR override below."><input type="checkbox" id="sam3FreezeLanguage" /> Freeze language backbone (preserve base text prompts)</label>
                        </div>
                        <div class="training-field">
                            <label for="sam3LanguageLr">Language backbone LR override</label>
                            <input type="number" id="sam3LanguageLr" step="0.000001" min="0" placeholder="‚âà5e-5 √ó LR scale (default)" />
                            <div class="training-help">Optional: set a specific LR for the text encoder. Set to 0 (or check ‚ÄúFreeze language‚Äù) to keep base vocabulary; leave blank to use the config default.</div>
                        </div>
                        <div class="training-field">
                            <label for="sam3PromptVariants">Prompt variants per class (text grounding)</label>
                            <textarea id="sam3PromptVariants" rows="3" placeholder="class_one: variant a, variant b&#10;hard_hat: helmet, safety helmet"></textarea>
                            <div class="training-help">One class per line: <code>class_name: alt1, alt2</code>. We swap the class name for one of these phrases during training; leave blank to use the class names as-is.</div>
                            <div class="training-toggle-row">
                                <label title="When on, pick a random variant per datapoint during training; when off, always use the first variant. Validation always uses the first variant."><input type="checkbox" id="sam3PromptRandomize" checked /> Randomize variants per datapoint</label>
                            </div>
                        </div>
                        <div class="training-toggle-row">
                            <label title="Keep the SAM3 segmentation head loaded so text prompting works. Uses the base head weights if you don‚Äôt train masks."><input type="checkbox" id="sam3SegHead" checked /> Keep segmentation head for text prompts</label>
                        </div>
                        <div class="training-toggle-row">
                            <label title="Only turn this on if your dataset includes segmentation masks. It will feed masks into training and update the segmentation head; leave off for bbox-only datasets (head stays frozen for prompting)."><input type="checkbox" id="sam3SegTrain" /> Train segmentation head with masks (requires masks)</label>
                            <div class="training-help">Default OFF for bbox-only runs. Turn ON only when you have mask annotations and want the segmentation head to learn them; otherwise the head stays frozen but still serves text prompts.</div>
                        </div>
                        <div class="training-toggle-row">
                            <label title="Disables the segmentation head entirely. Smaller checkpoints, faster training, BUT no text prompting and only bbox refinement works."><input type="checkbox" id="sam3BBoxOnly" /> Bbox-refiner only mode (no text prompts, no masks)</label>
                            <div class="training-help">Use only if you explicitly want a bbox-only refiner. Default OFF so text prompting remains available.</div>
                        </div>
                        <button type="button" id="sam3StartBtn" class="training-button">Start SAM3 Training</button>
                            <div class="training-note">
                                <strong>Tuning tips:</strong><br />
                                ‚Ä¢ Lower LR scale (e.g., 0.05 or 0.02) to reduce early loss spikes.<br />
                                ‚Ä¢ Meta‚Äôs default LR scale is 0.1; that makes transformer LR 8e-5, vision 2.5e-5, language 5e-6. Halving/dropping LR scale makes starts gentler.<br />
                                ‚Ä¢ Warmup steps: start near-zero LR and ramp up over these steps; higher is gentler/safer, lower is hotter/risks spikes (try 20‚Äì100).<br />
                                ‚Ä¢ Timescale: stretches the LR schedule; higher keeps LR steady longer, lower decays faster (try 20‚Äì40 for short runs).<br />
                                ‚Ä¢ To simulate larger batches without extra VRAM, keep batch size at 1 and raise grad accumulation (e.g., 2‚Äì4).<br />
                                ‚Ä¢ Typical recipe: resolution 1008, LR scale 0.05, grad accumulation 2, batch sizes 1/1, epochs 20.
                            </div>
                        <div class="training-note">
                            <strong>Text prompt alignment (read this):</strong><br />
                            ‚Ä¢ SAM3 class scores come from text embeddings. If you leave variants blank, we use your raw class names as prompts.<br />
                            ‚Ä¢ Weird names (e.g., <code>light_vehicle</code>) often don‚Äôt match the base model. Add synonyms per class or unfreeze the language backbone (set a small LR, or uncheck ‚ÄúFreeze language‚Äù).<br />
                            ‚Ä¢ Freezing the language encoder is only sensible if you stick to the base vocabulary and just fine-tune boxes/masks.<br />
                            ‚Ä¢ COCO eval is class-ID based; bad prompt alignment ‚áí wrong class IDs ‚áí low AP even if boxes look reasonable.
                        </div>
                        <div class="training-message" id="sam3Message" role="status"></div>
                    </section>
                    <section class="training-status-section">
                        <h2>Training Status</h2>
                        <div class="training-progress" id="sam3ProgressBar">
                            <div class="training-progress-fill" id="sam3ProgressFill"></div>
                        </div>
                        <div class="training-status-text" id="sam3StatusText">Idle</div>
                        <div class="training-help" id="sam3EtaText">ETA: estimating‚Ä¶</div>
                        <div class="training-actions">
                            <button type="button" class="training-button training-button-danger" id="sam3CancelBtn" disabled>Cancel Job</button>
                        </div>
                        <div class="training-summary" id="sam3Summary"></div>
                        <div class="training-summary" id="sam3BalanceSummary"></div>
                        <div class="training-actions">
                            <button type="button" class="training-button" id="sam3ActivateBtn" disabled>Activate checkpoint</button>
                        </div>
                        <div class="training-chart">
                            <h3>Loss</h3>
                            <canvas id="sam3LossChart" height="120"></canvas>
                            <div class="training-chart-legend">
                                <span class="legend-item legend-blue">Blue: rolling average loss (last ~10 batches; computed every batch even if not all are logged).</span>
                                <span class="legend-item legend-orange">Orange: logged batch loss (printed every Nth minibatch; some batches are skipped in logs).</span>
                                <span class="legend-item">Log lines show <code>batch=</code> and <code>avg10=</code> (last ~10 minibatches).</span>
                                <div class="training-help">
                                    Smoothed trend (EMA): <input type="range" id="sam3TrendSmooth" min="0.01" max="0.5" step="0.01" value="0.05" />
                                    <span id="sam3TrendSmoothValue">0.05</span> (lower = smoother)
                                </div>
                            </div>
                        </div>
                        <div class="training-chart">
                            <h3>Validation (COCO bbox)</h3>
                            <div id="sam3ValMetrics" class="training-help">No validation metrics yet.</div>
                        </div>
                        <div class="training-logs">
                            <h3>Logs</h3>
                            <pre id="sam3Log"></pre>
                        </div>
                        <div class="training-history">
                            <h3>Recent SAM3 Jobs</h3>
                            <div id="sam3TrainingHistory"></div>
                        </div>
                        <div class="training-history">
                            <div class="storage-header">
                                <h3>Run storage (logs & checkpoints)</h3>
                                <button type="button" class="training-button" id="sam3StorageRefresh">Refresh</button>
                            </div>
                            <div class="training-help">Lists folders under <code>uploads/sam3_runs/</code>; delete logs/dumps/checkpoints you no longer need.</div>
                            <div id="sam3StorageList" class="storage-list"></div>
                        </div>
                    </section>
                </div>
            </div>
	            <div class="tab-panel" id="tabAgentMining" data-tab-panel="agent-mining">
	                <div class="training-wrapper two-col">
	                    <section class="training-form-section">
	                        <h2>SAM3 Recipe Mining</h2>
	                        <p class="training-help">Automatically discover ‚Äúrecipes‚Äù that help SAM3 find each class in your dataset. A recipe is a portable zip file (JSON + example crops) you can reuse in the labeling panel.</p>
	                        <div class="training-field">
	                            <label>Dataset</label>
	                            <div class="sam3-dataset-row">
	                                <select id="agentDatasetSelect"></select>
	                                <button type="button" class="training-button" id="agentDatasetRefresh">Refresh</button>
	                            </div>
                            <div class="training-help" id="agentDatasetSummary">Pick a converted SAM3/Qwen dataset.</div>
		                        </div>
			                        <div class="training-grid">
			                            <div>
			                                <label for="agentValPercent">Val %<span class="help-icon" title="How many images are held out for evaluation.&#10;We split your dataset into Train and Val.&#10;Mining uses Train; scoring uses Val.&#10;Higher = more reliable scores (slower).&#10;Lower = faster but noisier scores.">?</span></label>
			                                <input type="number" id="agentValPercent" min="5" max="95" value="30" title="How many images are held out to test the recipe. Example: 30 means we test on 30% of images." />
			                            </div>
			                            <div>
			                                <label for="agentSplitSeed">Split seed<span class="help-icon" title="Random seed for the train/val split.&#10;Same seed = same split (repeatable).&#10;Change it if you want a different random split.&#10;Default is 42.">?</span></label>
			                                <input type="number" id="agentSplitSeed" value="42" title="Same seed = same train/val split. Change it if you want a different random split." />
			                            </div>
			                            <div class="training-field training-field--inline">
			                                <label for="agentReuseSplit">Reuse cached split<span class="help-icon" title="Reuse the cached train/val split for this dataset+seed. Turn off to rebuild the split (still deterministic).">?</span></label>
			                                <input type="checkbox" id="agentReuseSplit" checked />
			                            </div>
			                            <div>
			                                <label for="agentIouThreshold">Match overlap (Eval IoU)<span class="help-icon" title="Used only for scoring (evaluation), not for running the recipe.&#10;IoU = how much the predicted box overlaps the ground-truth box (0‚Äì1).&#10;0.5 ‚âà ‚Äúat least about half overlap‚Äù.&#10;Higher = stricter scoring (coverage may look lower).">?</span></label>
			                                <input type="number" id="agentIouThreshold" step="0.05" min="0" max="1" value="0.5" />
			                            </div>
			                        </div>
			                        <div class="training-grid">
			                            <div>
			                                <label for="agentSeedThreshold">Seed text threshold<span class="help-icon" title="First pass on each image: run the text prompt(s) and keep boxes with score ‚â• this.&#10;Lower = more candidate boxes (better recall, more noise, slower).&#10;Higher = fewer boxes (cleaner/faster, can miss objects).">?</span></label>
			                                <input type="number" id="agentSeedThreshold" step="0.01" min="0" max="1" value="0.05" />
			                            </div>
			                            <div>
			                                <label for="agentExpandThreshold">Expand threshold<span class="help-icon" title="Second pass (optional): after choosing seed boxes, we run a refine/expand pass from those boxes.&#10;This threshold controls how strict that refine pass is.&#10;Higher = fewer but cleaner results.">?</span></label>
			                                <input type="number" id="agentExpandThreshold" step="0.01" min="0" max="1" value="0.3" />
			                            </div>
			                            <div>
			                                <label for="agentMaxVisualSeeds">Max visual seeds<span class="help-icon" title="How many seed boxes per image we select for the refine/expand pass.&#10;0 = skip refine/expand (only use seed text detections).&#10;Higher = more compute; can increase coverage on hard objects.">?</span></label>
			                                <input type="number" id="agentMaxVisualSeeds" min="0" value="25" />
			                            </div>
			                            <div>
			                                <label for="agentSeedDedupeIou">Seed de-dupe overlap (IoU)<span class="help-icon" title="After the seed text pass, we remove near-duplicate seed boxes.&#10;If two seed boxes overlap more than this IoU, we keep one.&#10;Higher (e.g., 0.9) only removes almost-identical boxes.&#10;Lower removes more overlaps (can collapse crowded scenes).">?</span></label>
			                                <input type="number" id="agentSeedDedupeIou" step="0.05" min="0" max="1" value="0.9" />
			                            </div>
			                            <div>
			                                <label for="agentDedupeIou">Output de-dupe overlap (IoU)<span class="help-icon" title="Final de-duplication across all detections the recipe outputs.&#10;If two output boxes overlap more than this IoU, we keep the best one.&#10;Lower = more aggressive de-dup (fewer duplicates; may drop close objects).&#10;Higher = allows more overlaps (risk duplicate labels).">?</span></label>
			                                <input type="number" id="agentDedupeIou" step="0.05" min="0" max="1" value="0.5" />
			                            </div>
			                            <div>
			                                <label for="agentSimilarityScore">Image similarity filter (CLIP)<span class="help-icon" title="Crop-bank mode only.&#10;For each candidate box, we crop the image and compare it to saved example crops using CLIP.&#10;We keep boxes with similarity ‚â• this number.&#10;Higher = stricter (fewer false positives, can miss true positives).&#10;Ignored when a pretrained CLIP head is selected.">?</span></label>
			                                <input type="number" id="agentSimilarityScore" step="0.01" min="0" max="1" value="0.25" />
			                            </div>
			                        </div>
			                        <div class="training-grid">
			                            <div>
			                                <label for="agentMaskThreshold">Mask threshold<span class="help-icon" title="Polygons only.&#10;Controls how the mask is turned into a polygon (higher trims uncertain pixels).&#10;Higher = tighter/smaller shapes; lower = looser/bigger shapes.">?</span></label>
			                                <input type="number" id="agentMaskThreshold" step="0.05" min="0" max="1" value="0.5" />
			                            </div>
			                            <div>
			                                <label for="agentMaxResults">Max dets/image<span class="help-icon" title="Safety cap: maximum number of detections kept per image per prompt/pass.&#10;Prevents runaway outputs on noisy prompts.&#10;If too low, crowded images may be clipped.">?</span></label>
			                                <input type="number" id="agentMaxResults" min="1" value="100" />
			                            </div>
			                            <div>
			                                <label for="agentMinSize">Min area (px¬≤)<span class="help-icon" title="Drop detections smaller than this pixel area.&#10;Useful to remove tiny specks.&#10;0 keeps all (including very small objects).">?</span></label>
			                                <input type="number" id="agentMinSize" min="0" value="0" />
			                            </div>
			                            <div>
			                                <label for="agentSimplifyEps">Simplify Œµ<span class="help-icon" title="Polygons only.&#10;Douglas‚ÄìPeucker simplification in pixels.&#10;Higher = fewer points (simpler shapes).&#10;0 = no simplification (max detail).">?</span></label>
			                                <input type="number" id="agentSimplifyEps" min="0" step="0.1" value="0.0" />
			                            </div>
			                        </div>
			                        <div class="training-grid">
			                            <div>
			                                <label for="agentExemplars">Example crops/class<span class="help-icon" title="Crop-bank mode only.&#10;How many positive example cut-outs we save into the recipe zip for each class.&#10;More examples can reduce false positives but increases mining time and zip size.&#10;Ignored when a pretrained CLIP head is selected.">?</span></label>
			                                <input type="number" id="agentExemplars" min="0" value="20" />
			                            </div>
			                            <div>
			                                <label for="agentExemplarPoolValue">Candidate pool size<span class="help-icon" title="Crop-bank mode only.&#10;We build a pool of labeled boxes from the training split, then choose diverse examples from that pool.&#10;This controls how many candidate boxes we consider before picking the final crops.&#10;Bigger = more diversity, more CLIP work.">?</span></label>
			                                <input type="number" id="agentExemplarPoolValue" min="1" value="25" />
			                            </div>
			                            <div>
			                                <label for="agentExemplarPoolMode">Pool mode<span class="help-icon" title="How to interpret ‚Äúcandidate pool size‚Äù.&#10;% mode: pool = that percent of all labeled boxes for the class.&#10;Count mode: pool = fixed number of boxes.&#10;Only used when selecting example crops.">?</span></label>
			                                <select id="agentExemplarPoolMode">
			                                    <option value="percent" selected>% of labeled objects</option>
			                                    <option value="count">Fixed count</option>
			                                </select>
			                            </div>
			                            <div class="training-field training-field--inline">
			                                <label for="agentClusterExemplars">Diversify crops<span class="help-icon" title="Crop-bank mode only.&#10;Try to pick different-looking example crops (sizes/angles) instead of many near-identical ones.&#10;Recommended on.&#10;Ignored when a pretrained CLIP head is selected.">?</span></label>
			                                <input type="checkbox" id="agentClusterExemplars" checked />
			                            </div>
			                            <div class="training-field training-field--inline">
			                                <label for="agentClipGuard">Use CLIP filter<span class="help-icon" title="Crop-bank mode only.&#10;Use CLIP image similarity to keep detections that look like your saved example crops, and (optionally) suppress detections that look like negatives.&#10;Recommended on.&#10;Ignored when a pretrained CLIP head is selected.">?</span></label>
			                                <input type="checkbox" id="agentClipGuard" checked />
			                            </div>
			                        </div>
			                        <div class="training-grid">
				                            <div>
				                                <label for="agentClipHeadSelect">Pretrained CLIP head (optional)<span class="help-icon" title="Optional: use a pretrained CLIP classifier head (trained earlier on your dataset) to filter detections.&#10;The head is embedded into saved recipe zips (portable).&#10;When selected, crop-bank settings (example crops / CLIP similarity / negatives) are disabled and the head is used instead.">?</span></label>
					                                <select id="agentClipHeadSelect">
					                                    <option value="">(none)</option>
					                                </select>
					                                <div class="training-help">Select a classifier under <code>uploads/classifiers/</code> (trained via the CLIP tab or uploaded). When selected, crop-bank settings (example crops / CLIP similarity / negatives) are disabled and the head is used instead.</div>
					                            </div>
				                            <div>
				                                <label for="agentClipHeadMinProb">Head min prob<span class="help-icon" title="CLIP head mode only.&#10;Minimum probability required for the target class.&#10;Higher = fewer detections, cleaner results; lower = more detections (more false positives).">?</span></label>
				                                <input type="number" id="agentClipHeadMinProb" step="0.05" min="0" max="1" value="0.5" />
				                            </div>
			                            <div>
			                                <label for="agentClipHeadMargin">Head margin<span class="help-icon" title="CLIP head mode only.&#10;Require the target class probability to beat the best other class by this margin.&#10;0 disables the margin check.&#10;Higher can reduce confusion between similar classes.">?</span></label>
			                                <input type="number" id="agentClipHeadMargin" step="0.05" min="0" max="1" value="0.0" />
			                            </div>
			                        </div>
			                        <div class="training-grid">
			                            <div class="training-field training-field--inline">
			                                <label for="agentUseNegExemplars">Use negative crops<span class="help-icon" title="Crop-bank mode only.&#10;Helps reduce false positives (e.g., scooters mistaken as cars) by learning what ‚Äúnot this class‚Äù looks like from other classes.&#10;Ignored when a pretrained CLIP head is selected.">?</span></label>
			                                <input type="checkbox" id="agentUseNegExemplars" checked />
			                            </div>
				                            <div>
				                                <label for="agentMaxNegExemplars">Max negatives/class<span class="help-icon" title="Crop-bank mode only.&#10;How many negative example crops we collect from other classes.&#10;Negatives suppress detections that look like another class.&#10;More negatives can reduce false positives but costs time and increases recipe zip size.&#10;Ignored when a pretrained CLIP head is selected.">?</span></label>
				                                <input type="number" id="agentMaxNegExemplars" min="0" max="256" value="25" />
				                            </div>
			                            <div>
			                                <label for="agentNegStrength">Negative filter strength<span class="help-icon" title="Crop-bank mode only.&#10;How strongly negative crops suppress detections.&#10;0 disables negatives.&#10;Higher = more suppression (fewer false positives; can also remove true positives).&#10;Ignored when a pretrained CLIP head is selected.">?</span></label>
			                                <input type="number" id="agentNegStrength" step="0.05" min="0" max="5" value="0.5" />
			                            </div>
			                        </div>
		                        <div class="two-col-grid">
		                            <div>
		                                <label for="agentClasses">Class IDs (optional)<span class="help-icon" title="Optional: restrict mining to specific class IDs. Leave blank to mine all classes.&#10;Example: 1,2,5">?</span></label>
		                                <input type="text" id="agentClasses" placeholder="blank = all" />
		                            </div>
		                            <div>
		                                <label for="agentQwenMaxPrompts">Extra text prompts/class<span class="help-icon" title="Ask GPT-OSS for additional words to try for each class (in addition to the class name).&#10;0 = only use the class name; higher values try more alternative phrases.">?</span></label>
		                                <input type="number" id="agentQwenMaxPrompts" min="0" max="20" value="0" title="0 = only use the class name; higher values try more alternative phrases." />
		                            </div>
		                            <div>
		                                <label for="agentPromptReasoning">GPT-OSS reasoning<span class="help-icon" title="Controls how much the model ‚Äúthinks‚Äù before proposing extra words.&#10;Higher can be slower and less stable.&#10;We recommend ‚Äúnone‚Äù for now.">?</span></label>
		                                <select id="agentPromptReasoning" title="How much GPT-OSS ‚Äúthinks‚Äù before proposing extra words. Higher uses more time and can be less stable.">
		                                    <option value="none" selected>none (fastest)</option>
	                                    <option value="low">low</option>
	                                    <option value="medium">medium</option>
	                                    <option value="high">high</option>
	                                </select>
	                                <div class="training-help" style="color: #b91c1c;">Only ‚Äúnone‚Äù is stable right now.</div>
		                            </div>
		                            <div>
		                                <label for="agentPromptMaxTokens">GPT-OSS max tokens<span class="help-icon" title="Maximum length of the model output when proposing extra prompts.&#10;Higher can be slower and use more GPU memory.&#10;If you see truncated lists, increase this.">?</span></label>
		                                <input type="number" id="agentPromptMaxTokens" min="16" max="400" value="160" title="Maximum length of GPT-OSS output when proposing extra words." />
		                            </div>
		                            <div class="training-field training-field--inline training-field--inline-tight">
		                                <label for="agentTestMode">Test mode<span class="help-icon" title="Runs on a small number of images so you can verify everything works (fast).">?</span></label>
		                                <input type="checkbox" id="agentTestMode" checked />
			                            </div>
		                            <div>
		                                <label for="agentTrainLimit">Test train imgs<span class="help-icon" title="Test mode only.&#10;Number of training images sampled for mining.&#10;Smaller = faster smoke test.">?</span></label>
		                                <input type="number" id="agentTrainLimit" min="1" value="10" />
	                            </div>
	                            <div>
	                                <label for="agentValLimit">Test val imgs<span class="help-icon" title="Test mode only.&#10;Number of validation images sampled for scoring.&#10;Smaller = faster smoke test; larger = more reliable scores.">?</span></label>
	                                <input type="number" id="agentValLimit" min="1" value="10" />
	                            </div>
		                        </div>
				                        <div class="training-field">
				                            <label for="agentExtraPrompts">Extra prompts (optional)<span class="help-icon" title="Optional JSON dict of extra prompts to try.&#10;Keys: class names.&#10;Values: lists of strings.&#10;Special key ‚Äú__base__‚Äù applies to all classes.&#10;These are appended to GPT-OSS suggestions.">?</span></label>
				                            <textarea id="agentExtraPrompts" rows="8" style="min-width: 480px;" placeholder='{"__base__": ["object", "small object"], "light_vehicle": ["car", "sedan"], "person": ["human", "pedestrian"]}' title="Optional JSON dict of class_name -> list of extra prompt phrases. Special key &quot;__base__&quot; applies to all classes. Example: {&quot;__base__&quot;: [&quot;object&quot;, &quot;small object&quot;], &quot;light_vehicle&quot;: [&quot;car&quot;, &quot;sedan&quot;]}"></textarea>
				                            <div class="training-help">Optional extra words/phrases to try. They are appended to GPT-OSS suggestions. Use &quot;__base__&quot; to add prompts for all classes.</div>
				                            <div class="training-help" id="agentExtraPromptsParseStatus" aria-live="polite"></div>
				                        </div>
                        <div class="training-actions">
                            <button type="button" class="training-button" id="agentRunBtn">Run SAM3 Recipe Mining</button>
                            <button type="button" class="training-button secondary" id="agentRefreshBtn">Refresh latest</button>
	                            <button type="button" class="training-button danger" id="agentCancelBtn">Cancel job</button>
	                        </div>
	                        <div class="training-message" id="agentStatus" role="status">Idle</div>
	                        <div class="training-help" id="agentCacheSize">Cache: ‚Ä¶</div>
	                        <div class="training-progress" aria-hidden="true">
	                            <div id="agentProgressFill" class="training-progress-fill"></div>
	                        </div>
	                        <div class="training-help" id="agentProgressText" aria-live="polite"></div>
	                    </section>
	                    <section class="training-status-section">
		                        <details class="training-card" open>
		                            <summary style="font-weight: 600; cursor: pointer;">Agent Mining overview</summary>
		                            <div class="training-card__body">
		                                <p><strong>In plain English:</strong> You already have a labeled dataset. Agent Mining tries lots of ways to find the same objects automatically, then saves the best ‚Äúrecipe‚Äù so you can auto-label new images with fewer mistakes.</p>
		                                <p><strong>What ‚ÄúGreedy‚Äù means here:</strong> We build one ‚Äúwide net‚Äù recipe per class (text ‚Üí filter ‚Üí refine ‚Üí de-dupe). It keeps anything that passes the filters instead of doing a complex multi-step search over many combinations.</p>
		                                <ol>
		                                    <li><strong>Split:</strong> We split your dataset into ‚Äútrain‚Äù (to pick example crops) and ‚Äúval‚Äù (to test how good the recipe is). The split is repeatable using the seed.</li>
		                                    <li><strong>Words:</strong> We try the class name (and optional extra phrases) to ask SAM3 to propose candidate boxes.</li>
		                                    <li><strong>Example crops (optional):</strong> If you are using crop-bank mode, we save a small set of example cut-outs of the object from your dataset (e.g., a few cars of different sizes/angles). If you select a pretrained CLIP head, we skip crops and use the head instead.</li>
		                                    <li><strong>Seed boxes:</strong> On each validation image we run a very ‚Äúloose‚Äù text pass to get lots of candidate boxes.</li>
		                                    <li><strong>Filter:</strong> We keep boxes that look like the target class (either by comparing to example crops with CLIP, or by using the pretrained CLIP head probabilities). Optional negative crops can suppress common confusions in crop-bank mode.</li>
		                                    <li><strong>Refine:</strong> We optionally run a second SAM3 pass starting from selected boxes to improve coverage/quality.</li>
		                                    <li><strong>Remove duplicates:</strong> If two detections overlap heavily, we keep the best one so the same object isn‚Äôt labeled twice.</li>
		                                    <li><strong>Score:</strong> We measure how many ground-truth objects were found (‚Äúcoverage‚Äù) and how many extra/wrong boxes were added (‚Äúfalse positives‚Äù).</li>
		                                    <li><strong>Portable output:</strong> Saved recipes export as a zip containing <code>recipe.json</code> + all crops under <code>crops/</code> so you can copy it to another machine.</li>
		                                </ol>
	                                <ul class="training-help" style="margin-top: 10px;">
	                                    <li><strong>SAM3:</strong> the model that proposes boxes/polygons when you give it words (text prompt) or a box (visual prompt).</li>
	                                    <li><strong>CLIP:</strong> an image ‚Äúsimilarity checker‚Äù we use to decide whether a candidate box looks like your saved examples.</li>
	                                    <li><strong>Threshold:</strong> how confident the model must be before we keep a box; lower = more boxes (more noise), higher = fewer (cleaner).</li>
	                                    <li><strong>Overlap (IoU):</strong> how much two boxes overlap; we use it to decide ‚Äúsame object‚Äù for de-duplication and scoring.</li>
	                                    <li><strong>Coverage:</strong> how many true objects we found (higher is better).</li>
	                                    <li><strong>False positives:</strong> boxes we found that are not actually that class (lower is better).</li>
	                                </ul>
	                                <p class="training-help" style="margin-top: 10px;"><strong>Typical workflow:</strong> Pick a dataset ‚Üí keep test mode on ‚Üí run mining ‚Üí review results ‚Üí save the best class recipes ‚Üí go back to the labeling tab and apply the saved recipe presets to new images.</p>
	                                <p class="training-help">Tip: Start with test mode first. If disk usage grows, use ‚ÄúPurge cache‚Äù to delete cached detections (it only affects speed, not your datasets).</p>
	                            </div>
	                        </details>
                        <h3>Progress & Logs</h3>
                        <div class="training-help">Live status and logs for the latest SAM3 Recipe Mining job.</div>
                        <div class="training-actions">
                            <button type="button" class="training-button danger" id="agentPurgeCacheBtn" title="Purge cached detections to free disk space.">Purge cache</button>
                        </div>
                        <div class="training-logs" style="margin-bottom: 12px;">
                            <div id="agentLogs" class="training-log" style="max-height: 220px;"></div>
                        </div>
	                        <div class="training-divider"></div>
	                        <h3>Results</h3>
	                        <div class="training-help">Coverage = % of ground-truth objects found. FPs = extra detections that shouldn‚Äôt be there. Higher coverage and lower FPs is better.</div>
	                        <div id="agentResults"></div>
		                        <div class="training-divider"></div>
		                        <h3>Saved Recipes</h3>
		                        <div class="training-grid agent-recipe-controls">
		                            <div class="training-field">
		                                <label for="agentRecipeSelect">Recipes for this dataset<span class="help-icon" title="Saved recipe zips on the backend. Use Refresh if you just mined or imported a recipe.">?</span></label>
		                                <select id="agentRecipeSelect"></select>
		                            </div>
		                            <div class="training-field">
		                                <label for="agentRecipeImageId">Apply to dataset image id<span class="help-icon" title="Optional: run the selected recipe on a specific image from this dataset (by numeric COCO image id). If you‚Äôre labeling interactively, use the recipe presets in the labeling tab instead.">?</span></label>
		                                <input type="number" id="agentRecipeImageId" min="0" placeholder="e.g. 123" />
		                            </div>
		                            <div class="training-field">
		                                <div class="training-field training-field--inline training-field--inline-tight">
		                                    <label for="agentRecipeOverrideToggle">Override output class<span class="help-icon" title="Assign detections to a different class than the recipe‚Äôs default (only changes the label, not the detection).">?</span></label>
		                                    <input type="checkbox" id="agentRecipeOverrideToggle" />
		                                </div>
		                                <select id="agentRecipeOverrideSelect" disabled></select>
		                                <div class="training-help">Use a different label for the detections than the one stored in the recipe.</div>
		                            </div>
		                        </div>
		                        <div class="training-grid training-grid--buttons agent-recipe-actions">
		                            <button type="button" class="training-button" id="agentRecipeRefresh">Refresh list</button>
		                            <button type="button" class="training-button secondary" id="agentRecipeLoad">Load recipe</button>
		                            <button type="button" class="training-button secondary" id="agentRecipeDownload">Download zip</button>
		                            <button type="button" class="training-button secondary" id="agentRecipeApply">Apply to image</button>
		                        </div>
		                        <div class="training-field">
		                            <label for="agentRecipeFile">Import recipe zip<span class="help-icon" title="Import a recipe zip from another machine or previous run.&#10;The zip contains the recipe JSON plus any crops/weights needed, so it‚Äôs portable.">?</span></label>
		                            <div class="training-grid training-grid--buttons">
		                                <input type="file" id="agentRecipeFile" accept=".zip" />
		                                <button type="button" class="training-button secondary" id="agentRecipeImport">Import</button>
		                            </div>
		                            <div class="training-help">Packages include the recipe JSON plus exemplar crops so they are portable between machines.</div>
		                        </div>
		                        <div id="agentRecipeDetails" class="training-card" style="display: none;"></div>
		                        <div class="training-help">Pick a dataset, refresh, then load, download, import, or apply to a specific COCO image id.</div>
	                    </section>
	                </div>
	            </div>
            <div class="tab-panel" id="tabPromptHelper" data-tab-panel="prompt-helper">
                <div class="training-wrapper">
                    <section class="training-form-section">
                        <h2>SAM3 Vocabulary Explorer</h2>
                        <p class="training-help">Generate alternative text prompts for your dataset classes and score them with SAM3 on a sampled subset to find the best wording.</p>
                        <div class="training-field">
                            <label>Dataset</label>
                            <div class="sam3-dataset-row">
                                <select id="promptHelperDatasetSelect"></select>
                                <button type="button" class="training-button" id="promptHelperDatasetRefresh">Refresh</button>
                            </div>
                            <div class="training-help" id="promptHelperDatasetSummary">Pick a converted SAM3/Qwen dataset.</div>
                        </div>
                        <div class="training-grid">
                            <div>
                                <label for="promptHelperSampleSize">Images per class</label>
                                <input type="number" id="promptHelperSampleSize" min="1" value="20" title="How many images per class to sample for scoring prompts." />
                            </div>
                            <div>
                                <label for="promptHelperMaxSynonyms">Max extra prompts per class</label>
                                <input type="number" id="promptHelperMaxSynonyms" min="0" max="10" value="3" title="Number of alternative phrases to try (original name is always included)." />
                            </div>
                            <div>
                                <label for="promptHelperScoreThresh">Score threshold</label>
                                <input type="number" id="promptHelperScoreThresh" step="0.01" min="0" max="1" value="0.2" title="Drop detections below this score when scoring prompts." />
                            </div>
                            <div>
                                <label for="promptHelperMaxDets">Max detections/image</label>
                                <input type="number" id="promptHelperMaxDets" min="1" value="100" title="Keep only the top N detections per image when scoring prompts." />
                            </div>
                            <div>
                                <label for="promptHelperIouThresh">IoU threshold</label>
                                <input type="number" id="promptHelperIouThresh" step="0.05" min="0" max="1" value="0.5" title="IoU threshold for a match when comparing SAM3 boxes to ground truth." />
                            </div>
                            <div>
                                <label for="promptHelperSeed">Random seed</label>
                                <input type="number" id="promptHelperSeed" value="42" title="Controls image sampling so reruns are reproducible." />
                            </div>
                        </div>
                        <div class="training-toggle-row">
                            <label title="Use Qwen to brainstorm human-friendly phrases. Turn off to only use your raw class names + simple cleaned variants."><input type="checkbox" id="promptHelperUseQwen" checked /> Use Qwen to propose phrases</label>
                        </div>
                        <div class="training-actions">
                            <button type="button" class="training-button" id="promptHelperGenerateBtn">Generate prompts</button>
                            <button type="button" class="training-button" id="promptHelperEvaluateBtn" disabled>Evaluate with SAM3</button>
                        </div>
                        <div class="training-field">
                            <label>Prompt presets</label>
                            <div class="training-grid">
                                <div>
                                    <input type="text" id="promptHelperPresetName" placeholder="Preset name (optional)" />
                                    <button type="button" class="training-button" id="promptHelperPresetSave">Save prompts</button>
                                </div>
                                <div>
                                    <select id="promptHelperPresetSelect"></select>
                                    <button type="button" class="training-button" id="promptHelperPresetLoad">Load preset</button>
                                </div>
                            </div>
                            <div class="training-help">Save/load prompt sets for reuse with this dataset.</div>
                        </div>
                        <div class="training-note">
                            <strong>Flow:</strong> generate/edit prompts, then run evaluation. Scoring samples images per class, runs SAM3 text prompts one at a time, and reports precision/recall-style stats against ground truth boxes.
                        </div>
                        <div class="training-message" id="promptHelperMessage" role="status"></div>
                        <div class="training-divider"></div>
                        <h3>Prompt Search (beta)</h3>
                        <p class="training-help">Use your edited prompts above, then run a targeted search that samples positives and negatives to find the safest wording (prioritizes recall but penalizes prompts below a precision floor).</p>
                        <div class="training-field">
                            <label for="promptSearchClassSelect">Class to search</label>
                            <select id="promptSearchClassSelect" style="width: 100%; min-width: 200px;"></select>
                            <div class="training-help">Default is all classes. Pick one to iterate faster on a single label (generate prompts first to populate).</div>
                        </div>
                        <div class="training-grid">
                            <div>
                                <label for="promptSearchSampleSize">Positive images/class</label>
                                <input type="number" id="promptSearchSampleSize" min="1" value="20" title="How many images that contain the class to sample." />
                            </div>
                            <div>
                                <label for="promptSearchNegatives">Negative images/class</label>
                                <input type="number" id="promptSearchNegatives" min="0" value="20" title="How many images without the class to include (catches false positives)." />
                            </div>
                            <div>
                                <label for="promptSearchPrecisionFloor">Precision floor</label>
                                <input type="number" id="promptSearchPrecisionFloor" step="0.05" min="0" max="1" value="0.9" title="Prompts below this precision get penalized heavily in the search score." />
                            </div>
                            <div>
                                <label for="promptSearchScoreThresh">Score threshold</label>
                                <input type="number" id="promptSearchScoreThresh" step="0.01" min="0" max="1" value="0.2" title="Drop detections below this score when scoring prompts." />
                            </div>
                            <div>
                                <label for="promptSearchMaxDets">Max detections/image</label>
                                <input type="number" id="promptSearchMaxDets" min="1" value="100" title="Keep only the top N detections per image when searching." />
                            </div>
                            <div>
                                <label for="promptSearchIouThresh">IoU threshold</label>
                                <input type="number" id="promptSearchIouThresh" step="0.05" min="0" max="1" value="0.5" title="IoU threshold for a match when comparing SAM3 boxes to ground truth." />
                            </div>
                            <div>
                                <label for="promptSearchSeed">Random seed</label>
                                <input type="number" id="promptSearchSeed" value="42" title="Controls sampling so reruns are reproducible." />
                            </div>
                        </div>
                        <div class="training-actions">
                            <button type="button" class="training-button" id="promptSearchRunBtn">Search best prompts</button>
                        </div>
                        <div class="training-message" id="promptSearchMessage" role="status"></div>
                        <div class="training-note">
                            Uses the current prompt list above (including any edits or presets). Positive samples only include images with the class; negatives are sampled from images without the class to reveal false positives.
                        </div>
                        <div class="training-divider"></div>
                        <h3>Prompt Recipe Mining</h3>
                        <p class="training-help">Find an ordered set of prompts + thresholds that covers all GTs for a class with zero (or minimal) false positives.</p>
                        <div class="training-field">
                            <label for="promptRecipeClassSelect">Class to target</label>
                            <select id="promptRecipeClassSelect"></select>
                            <div class="training-help">Runs on a deterministic sample for this class.</div>
                        </div>
                        <div class="training-grid">
                            <div>
                                <label for="promptRecipeSampleSize">Positive images</label>
                                <input type="number" id="promptRecipeSampleSize" min="1" value="30" title="How many images containing the class to sample." />
                            </div>
                            <div>
                                <label for="promptRecipeNegatives">Negative images</label>
                                <input type="number" id="promptRecipeNegatives" min="0" value="10" title="How many images without the class to include for FP checks." />
                            </div>
                            <div>
                                <label for="promptRecipeThresholds">Thresholds (comma sep)</label>
                                <input type="text" id="promptRecipeThresholds" value="0.2,0.3,0.4" title="Score thresholds to try for each prompt." />
                            </div>
                            <div>
                                <label for="promptRecipeMaxDets">Max detections/image</label>
                                <input type="number" id="promptRecipeMaxDets" min="1" value="100" />
                            </div>
                            <div>
                                <label for="promptRecipeIouThresh">IoU threshold</label>
                                <input type="number" id="promptRecipeIouThresh" step="0.05" min="0" max="1" value="0.5" />
                            </div>
                            <div>
                                <label for="promptRecipeSeed">Random seed</label>
                                <input type="number" id="promptRecipeSeed" value="42" />
                            </div>
                            <div>
                                <label for="promptRecipeExpandCount">Qwen expand (max)</label>
                                <input type="number" id="promptRecipeExpandCount" min="0" max="50" value="10" title="How many new prompts to request from Qwen." />
                            </div>
                        </div>
                        <div class="training-actions">
                            <button type="button" class="training-button" id="promptRecipeExpandBtn">Expand prompts with Qwen</button>
                            <button type="button" class="training-button" id="promptRecipeRunBtn">Mine recipe</button>
                            <button type="button" class="training-button secondary" id="promptRecipeApplyBtn" title="Copy the last mined recipe prompts/thresholds into the prompt editor so you can save as a preset.">
                                Apply last recipe to prompts
                            </button>
                        </div>
                        <div class="training-message" id="promptRecipeMessage" role="status"></div>
                        <div class="training-note">Uses prompts for the selected class (edit in the list above). Runs on positives + optional negatives; tries each threshold per prompt and proposes an ordered recipe.</div>
                    </section>
                    <section class="training-status-section">
                        <h2>Prompts & Results</h2>
                        <div class="training-help" id="promptHelperStatus">Idle</div>
                        <div class="training-actions">
                            <button type="button" class="training-button" id="promptHelperApplyBtn" disabled>Apply top prompts to SAM3 training</button>
                        </div>
                        <div class="training-subsection">
                            <h4>Prompts to evaluate</h4>
                            <div id="promptHelperPrompts"></div>
                        </div>
                        <div class="training-subsection">
                            <h4>Evaluation log</h4>
                            <div id="promptHelperLogs" class="training-log"></div>
                        </div>
                        <div class="training-summary" id="promptHelperSummary"></div>
                        <div id="promptHelperResults" class="training-history"></div>
                        <div class="training-subsection">
                            <h4>Prompt Search (beta)</h4>
                            <div class="training-help" id="promptSearchStatus">Idle</div>
                            <div class="training-subsection">
                                <h5>Search log</h5>
                                <div id="promptSearchLogs" class="training-log"></div>
                            </div>
                            <div id="promptSearchResults" class="training-history"></div>
                            <div class="training-subsection">
                                <h5>Prompt Recipe Mining</h5>
                                <div class="training-help" id="promptRecipeStatus">Idle</div>
                                <div class="training-subsection">
                                    <h5>Recipe log</h5>
                                    <div id="promptRecipeLogs" class="training-log"></div>
                                </div>
                                <div id="promptRecipeResults" class="training-history"></div>
                            </div>
                        </div>
                    </section>
                </div>
            </div>
            <div class="tab-panel" id="tabDatasets" data-tab-panel="datasets">
                <div class="training-wrapper two-col">
                    <div class="training-card">
                        <div class="training-card__header">
                            <div class="training-card__title">Dataset Management</div>
                            <div class="training-help">Upload YOLO/YOLO-seg datasets once and reuse them across CLIP, Qwen, and SAM3 training.</div>
                        </div>
                        <div class="training-card__body dataset-manager">
                            <div class="training-subsection">
                                <div class="training-subsection__title">Upload current labeling session</div>
                                <div class="training-help">Packages the images + bboxes you have loaded in the labeling tab and caches them as a bbox dataset.</div>
                                <div class="training-actions">
                                    <button type="button" id="datasetUploadCurrentBtn" class="training-button">Upload current dataset</button>
                                    <div id="datasetUploadCurrentSummary" class="training-help"></div>
                                </div>
                            </div>
                            <div class="training-subsection">
                                <div class="training-subsection__title">Upload YOLO/YOLO-seg zip</div>
                                <label for="datasetUploadFile">Zip file (root: labelmap.txt + images + labels)</label>
                                <div class="training-help">
                                    Expect exactly: labelmap.txt (class names, one per line) at the root, plus images/ and labels/ in YOLO format. If you already have train/val splits, include them; otherwise a single images/labels pair is fine.
                                </div>
                                <input type="file" id="datasetUploadFile" accept=".zip" />
                                <div class="training-grid">
                                    <div>
                                        <label for="datasetUploadName">Dataset name (optional)</label>
                                        <input type="text" id="datasetUploadName" placeholder="Defaults to zip name" />
                                    </div>
                                    <div>
                                        <label for="datasetUploadType">Dataset type</label>
                                        <select id="datasetUploadType">
                                            <option value="">Auto-detect</option>
                                            <option value="bbox">BBox (YOLO)</option>
                                            <option value="seg">Polygon masks (YOLO-seg)</option>
                                        </select>
                                    </div>
                                </div>
                                <div class="training-actions">
                                    <button type="button" id="datasetUploadBtn" class="training-button">Upload dataset</button>
                                    <button type="button" id="datasetListRefresh" class="training-button training-button--ghost">Refresh list</button>
                                </div>
                                <div id="datasetUploadMessage" class="training-message"></div>
                            </div>
                        </div>
                    </div>
                    <div class="training-card">
                        <div class="training-card__header">
                            <div class="training-card__title">Datasets on disk</div>
                            <div class="training-help">All cached datasets discovered on disk. Use the refresh button after adding or removing datasets manually.</div>
                        </div>
                        <div class="training-card__body">
                            <div class="training-actions">
                                <button type="button" id="datasetListRefreshTop" class="training-button">Refresh list</button>
                            </div>
                            <div id="datasetList" class="training-history"></div>
                        </div>
                    </div>
                </div>
                <div class="training-card">
                    <div class="training-card__header">
                        <div class="training-card__title">Build segmentation datasets from bbox datasets</div>
                        <div class="training-help">Creates YOLO polygon masks using SAM (bbox ‚Üí polygon). Originals stay untouched.</div>
                    </div>
                    <div class="training-card__body">
                        <label for="segBuilderDatasetSelect">Source bbox dataset</label>
                        <select id="segBuilderDatasetSelect"></select>
                        <div id="segBuilderDatasetSummary" class="training-help">Pick a dataset to convert.</div>
                        <label for="segBuilderOutputName">Output dataset name</label>
                        <input type="text" id="segBuilderOutputName" placeholder="Defaults to &lt;dataset&gt;_seg" />
                        <label for="segBuilderVariant">SAM variant</label>
                        <select id="segBuilderVariant">
                            <option value="sam3">SAM 3</option>
                            <option value="sam1">SAM 1</option>
                        </select>
                        <div class="training-help">Polygons only (YOLO-seg). Output is kept separate; originals stay untouched.</div>
                        <div class="training-actions">
                            <button type="button" id="segBuilderStartBtn" class="training-button">Start build</button>
                            <button type="button" id="segBuilderRefreshBtn" class="training-button training-button--ghost">Refresh datasets</button>
                        </div>
                        <div id="segBuilderMessage" class="training-message"></div>
                        <div id="segBuilderLog" class="training-log"></div>
                    </div>
                    <div class="training-card__footer">
                        <div class="training-subsection__title">Segmentation build jobs</div>
                        <div id="segBuilderJobs" class="training-history"></div>
                        <div class="training-actions">
                            <button type="button" id="segBuilderJobsRefresh" class="training-button training-button--ghost">Refresh jobs</button>
                        </div>
                    </div>
                </div>
            </div>
            <div class="tab-panel" id="tabSam3PromptModels" data-tab-panel="sam3-prompt-models">
                <div class="training-wrapper single-wide">
                    <section class="training-form-section">
                        <h2>SAM3 Correction Model Selection</h2>
                        <p class="training-help">Pick a locally trained SAM3 checkpoint to use for bbox prompting in the labeling page.</p>
                        <div class="training-field">
                            <label for="sam3PromptModelSelect">Available models</label>
                            <div class="sam3-dataset-row">
                                <select id="sam3PromptModelSelect"></select>
                                <button type="button" class="training-button" id="sam3PromptRefresh">Refresh</button>
                            </div>
                            <div class="training-help" id="sam3PromptModelSummary"></div>
                        </div>
                        <div class="training-actions">
                            <button type="button" class="training-button" id="sam3PromptActivate">Activate model</button>
                        </div>
                        <div class="training-message" id="sam3PromptMessage" role="status"></div>
                    </section>
                </div>
            </div>
            <div class="tab-panel" id="tabActive" data-tab-panel="active">
                <div class="active-wrapper">
                    <section class="active-controls">
                        <h2>Switch Models</h2>
                        <div class="active-message" id="activeMessage" role="status"></div>
                        <p class="active-help">When you activate a trained classifier, the system loads the CLIP backbone saved in its metadata. Use these controls if you need to override the paths manually.</p>
                        <div class="active-field">
                            <label for="activeClipSelect">CLIP Backbone</label>
                            <select id="activeClipSelect"></select>
                            <div class="active-help">CLIP encoder that will run before the logistic regression head.</div>
                        </div>
                        <div class="active-field">
                            <label for="activeClassifierPath">Classifier Path</label>
                            <div class="active-picker">
                                <input type="text" id="activeClassifierPath" placeholder="./my_logreg_model.pkl" />
                                <button type="button" class="training-button" id="activeClassifierBrowse">Browse‚Ä¶</button>
                            </div>
                            <div class="active-help">Choose the logistic-regression `.pkl` returned by training.</div>
                        </div>
                        <div class="active-field">
                            <label for="activeLabelmapPath">Labelmap Path</label>
                            <div class="active-picker">
                                <input type="text" id="activeLabelmapPath" placeholder="Optional" />
                                <button type="button" class="training-button" id="activeLabelmapBrowse">Browse‚Ä¶</button>
                            </div>
                            <div class="active-help">Optional `.pkl`/`.txt` mapping to keep YOLO order.</div>
                        </div>
                        <div class="active-field active-fallback">
                            <h3>Fallback: Dilate Crop on Low Confidence</h3>
                            <p class="active-help">When Auto Class is on, CLIP may occasionally return a low-confidence score for a rough bbox. Enable this fallback to automatically enlarge (dilate) the crop and retry the prediction before surfacing an error.</p>
                            <label class="active-inline">
                                <input type="checkbox" id="useFallbackDilate" name="useFallbackDilate" />
                                Turn on fallback dilation when CLIP probability is below the threshold.
                            </label>
                            <div class="fallback-options">
                                <label for="minProba">Min CLIP confidence (0‚Äì1)</label>
                                <input type="number" id="minProba" name="minProba" min="0" max="1" step="0.05" value="0.55" />
                                <label for="dilateRatio">Dilate ratio</label>
                                <input type="number" id="dilateRatio" name="dilateRatio" min="0" max="1" step="0.05" value="0.10" />
                            </div>
                            <p class="active-help">Example: a 0.55 threshold + 0.10 ratio expands each low-confidence bbox by 10% in every direction before rerunning CLIP. Leave disabled if you prefer to review low-confidence crops manually.</p>
                        </div>
                        <div class="active-buttons">
                            <button type="button" class="training-button" id="activateLatestModelBtn" disabled>Activate Latest Training Run</button>
                            <button type="button" class="training-button" id="applyActiveModelBtn">Apply Changes</button>
                            <button type="button" class="training-button" id="refreshActiveModelBtn">Refresh</button>
                        </div>
                        <input type="file" id="activeClassifierUpload" accept=".pkl" class="file-input-hidden" />
                        <input type="file" id="activeLabelmapUpload" accept=".pkl,.txt" class="file-input-hidden" />
                    </section>
                </div>
            </div>
            <div class="tab-panel" id="tabQwen" data-tab-panel="qwen">
                <div class="qwen-models-wrapper">
                    <section class="qwen-models-list">
                        <h2>Qwen Models</h2>
                        <p class="qwen-models-help">Pick which fine-tuned adapters should power the Assist panel. Each run stores the exact prompts, context, and class list it learned from.</p>
                        <div class="qwen-model-status" id="qwenModelStatus">Loading‚Ä¶</div>
                        <div class="qwen-model-toolbar">
                            <button type="button" class="training-button" id="qwenModelRefreshBtn">Refresh</button>
                        </div>
                        <div class="qwen-model-grid" id="qwenModelList"></div>
                    </section>
                    <section class="qwen-model-details">
                        <h2>Active Model Details</h2>
                        <div id="qwenModelDetails" class="qwen-model-details__body"></div>
                    </section>
                </div>
            </div>
            <div class="tab-panel" id="tabPredictors" data-tab-panel="predictors">
                <div class="predictor-panel">
                    <div class="predictor-card">
                        <h2>Predictor Budget</h2>
                        <p>Choose how many SAM predictors stay loaded so you can flip between images without delays.</p>
                        <div class="predictor-control">
                            <label for="predictorCount">Concurrent predictors</label>
                            <div class="predictor-control-inline">
                                <input type="number" id="predictorCount" min="1" max="3" value="3" />
                                <button type="button" class="training-button" id="predictorApply">Apply</button>
                            </div>
                        </div>
                        <div class="predictor-message" id="predictorMessage"></div>
                    </div>
                    <div class="predictor-grid">
                        <div class="predictor-stat">
                            <span>Active slots</span>
                            <strong id="predictorActiveCount">--</strong>
                        </div>
                        <div class="predictor-stat">
                            <span>Loaded predictors</span>
                            <strong id="predictorLoadedCount">--</strong>
                        </div>
                        <div class="predictor-stat">
                            <span>Predictor RAM</span>
                            <strong id="predictorImageRam">--</strong>
                        </div>
                        <div class="predictor-stat">
                            <span>Process RAM</span>
                            <strong id="predictorProcessRam">--</strong>
                        </div>
                        <div class="predictor-stat">
                            <span>GPU free / total (fallback: system)</span>
                            <strong id="predictorSystemFreeRam">--</strong>
                        </div>
                    </div>
                </div>
            </div>
            <div class="tab-panel" id="tabSettings" data-tab-panel="settings">
                <div class="settings-panel">
                    <h3>Backend Connection</h3>
                    <p>The UI talks to the FastAPI server via an HTTP base URL. Enter the URL (including port) below to point the interface at a local or remote backend.</p>
                    <label for="settingsApiRoot">API base URL</label>
                    <input type="text" id="settingsApiRoot" placeholder="http://localhost:8000" />
                    <div class="settings-actions">
                        <button type="button" id="settingsApply" class="training-button">Save</button>
                        <button type="button" id="settingsTest" class="training-button">Test Connection</button>
                    </div>
                    <div id="settingsStatus" class="settings-status" role="status" aria-live="polite"></div>
                    <p class="settings-help">Tip: when tunnelling to a remote GPU box (e.g. <code>ssh -L 8000:127.0.0.1:8000 user@gpu-host</code>), set the URL to <code>http://localhost:8000</code> so the browser routes through the tunnel.</p>
                    <div class="training-divider"></div>
                    <h3>Backend Fuzzer</h3>
                    <p class="settings-help">Runs a quick smoke test with random data against key API endpoints (SAM/Qwen). Useful to sanity-check that the backend is alive and models are loaded. Tests may fail if weights are missing.</p>
                    <div class="training-grid">
                            <label><input type="checkbox" id="fuzzerIncludeQwen" checked /> Include Qwen tests</label>
                            <label><input type="checkbox" id="fuzzerIncludeSam3" /> Include SAM3 tests</label>
                            <label><input type="checkbox" id="fuzzerIncludeClip" /> Include CLIP tests</label>
                            <label><input type="checkbox" id="fuzzerIncludeAgent" /> Include Agent Mining tests</label>
                    </div>
                    <div class="settings-actions">
                        <button type="button" id="runBackendFuzzer" class="training-button">Run fuzzer</button>
                    </div>
                    <div id="backendFuzzerStatus" class="settings-status" role="status" aria-live="polite"></div>
                    <pre id="backendFuzzerLog" class="training-log" style="max-height: 220px; overflow-y: auto;"></pre>
                    <div class="training-divider"></div>
                    <h3>Default upload and payload limits</h3>
                    <p class="settings-help">
                        Defaults are tuned for LAN use. You can override any of these on the backend by setting
                        environment variables (e.g. <code>CLIP_TRAIN_UPLOAD_QUOTA_BYTES</code>,
                        <code>DATASET_ZIP_MAX_BYTES</code>, <code>AGENT_RECIPE_MAX_BYTES</code>,
                        <code>AGENT_MINING_CACHE_MAX_BYTES</code>, <code>MAX_RESPONSE_DETECTIONS</code>,
                        <code>SAM_PRELOAD_MAX_BYTES</code>, <code>FS_DIALOG_ENABLED</code>/<code>FS_DIALOG_ALLOW_REMOTE</code>).
                        If the backend is configured with lower limits, uploads over those caps will be rejected.
                    </p>
                    <ul class="settings-help">
                        <li>Dataset zips (SAM3/Qwen): up to ~100GB zip, ~50GB per entry.</li>
                        <li>CLIP/Qwen chunked uploads: ~10GB per file, ~100GB per job quota.</li>
                        <li>CLIP training uploads: ~10GB per file, ~100GB per job quota.</li>
                        <li>Classifier/labelmap/general assets: ~10GB per file, ~100GB per uploads quota.</li>
                        <li>Agent recipe zips: ~2GB total; crops capped (~1000 pngs / ~512MB total).</li>
                        <li>Responses: max ~5000 detections / 2000 masks; SAM preload cache ~2GB.</li>
                        <li>Agent mining cache: ~80GB default; TTL off by default (set <code>AGENT_MINING_CACHE_TTL_HOURS</code> to enable purge).</li>
                        <li>FS directory picker: controlled by <code>FS_DIALOG_ENABLED</code> (default on, localhost-only unless <code>FS_DIALOG_ALLOW_REMOTE</code> is true).</li>
                    </ul>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener("DOMContentLoaded", function() {
          if (typeof listenImageCrop === "function") {
            listenImageCrop();
          }
        });
        </script>
</body>
</html>
